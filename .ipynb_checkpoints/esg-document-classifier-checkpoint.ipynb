{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with ESG Document Classifier\n",
    "\n",
    "Write down plan here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U pypdfium2 wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T15:45:06.273642Z",
     "iopub.status.busy": "2023-06-02T15:45:06.273223Z",
     "iopub.status.idle": "2023-06-02T15:45:06.282024Z",
     "shell.execute_reply": "2023-06-02T15:45:06.281125Z",
     "shell.execute_reply.started": "2023-06-02T15:45:06.273601Z"
    }
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd \n",
    "import pypdfium2 as pdfium\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T15:45:06.283674Z",
     "iopub.status.busy": "2023-06-02T15:45:06.283375Z",
     "iopub.status.idle": "2023-06-02T15:45:06.299613Z",
     "shell.execute_reply": "2023-06-02T15:45:06.298548Z",
     "shell.execute_reply.started": "2023-06-02T15:45:06.283648Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pdf(path):\n",
    "    return pdfium.PdfDocument(path)\n",
    "\n",
    "def get_content(page):\n",
    "    textpage = page.get_textpage()\n",
    "    return textpage.get_text_range()\n",
    "\n",
    "def render(page):\n",
    "    bitmap = page.render(\n",
    "        scale = 1,    # 72dpi resolution\n",
    "        rotation = 0, # no additional rotation\n",
    "    )\n",
    "    return bitmap.to_pil()\n",
    "\n",
    "def extract_content_from_id(file_id: str) -> str :    \n",
    "    # extract filename and page\n",
    "    items = file_id.split('.')\n",
    "    filename = '.'.join(items[:2])\n",
    "    page_num = int(items[-1])-1\n",
    "    \n",
    "    # load pdf, select page, and extract its content\n",
    "    filepath = os.path.join(report_path, filename)\n",
    "    pdf = get_pdf(filepath)\n",
    "    page = pdf[page_num]\n",
    "    content = get_content(page)\n",
    "\n",
    "    content = \" \".join(content.lower().split())\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set path for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T15:45:06.441576Z",
     "iopub.status.busy": "2023-06-02T15:45:06.441152Z",
     "iopub.status.idle": "2023-06-02T15:45:06.452465Z",
     "shell.execute_reply": "2023-06-02T15:45:06.451298Z",
     "shell.execute_reply.started": "2023-06-02T15:45:06.441538Z"
    }
   },
   "outputs": [],
   "source": [
    "# online Kaggle data path\n",
    "\n",
    "# basepath = \"/kaggle/input/oxml2023mlcases-esg-classifier/data/\"\n",
    "# report_path = os.path.join(basepath, \"reports\")\n",
    "# label_path = os.path.join(basepath, \"labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local data path\n",
    "\n",
    "basepath = \"/Users/macmini/Desktop/GoogleDrive/OxML_2023/code/Kaggle\"\n",
    "\n",
    "# report path\n",
    "report_path = os.path.join(basepath, \"data\", \"reports\")\n",
    "\n",
    "# label path\n",
    "label_path = os.path.join(basepath, \"data\", \"labels.csv\")\n",
    "\n",
    "print(\"Report path: \", report_path)\n",
    "print(\"Label path: \", label_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T15:45:06.454736Z",
     "iopub.status.busy": "2023-06-02T15:45:06.454248Z",
     "iopub.status.idle": "2023-06-02T15:45:06.484145Z",
     "shell.execute_reply": "2023-06-02T15:45:06.482729Z",
     "shell.execute_reply.started": "2023-06-02T15:45:06.454697Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(label_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T15:45:06.485821Z",
     "iopub.status.busy": "2023-06-02T15:45:06.485377Z",
     "iopub.status.idle": "2023-06-02T15:45:51.101406Z",
     "shell.execute_reply": "2023-06-02T15:45:51.100569Z",
     "shell.execute_reply.started": "2023-06-02T15:45:06.48578Z"
    }
   },
   "outputs": [],
   "source": [
    "contents = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    file_id = row['id']\n",
    "    content = extract_content_from_id(file_id)\n",
    "    contents.append(content)\n",
    "    \n",
    "df['content'] = contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T15:45:51.106951Z",
     "iopub.status.busy": "2023-06-02T15:45:51.106574Z",
     "iopub.status.idle": "2023-06-02T15:45:51.119965Z",
     "shell.execute_reply": "2023-06-02T15:45:51.119Z",
     "shell.execute_reply.started": "2023-06-02T15:45:51.106919Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T15:45:51.122071Z",
     "iopub.status.busy": "2023-06-02T15:45:51.121584Z",
     "iopub.status.idle": "2023-06-02T15:45:51.25988Z",
     "shell.execute_reply": "2023-06-02T15:45:51.258593Z",
     "shell.execute_reply.started": "2023-06-02T15:45:51.122023Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing and tokenize each page\n",
    "all_tokens = []\n",
    "page_len = []\n",
    "for x in df['content']:\n",
    "    tokens = x.split()\n",
    "    page_len.append(len(tokens))\n",
    "    all_tokens += tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T15:45:51.262063Z",
     "iopub.status.busy": "2023-06-02T15:45:51.261623Z",
     "iopub.status.idle": "2023-06-02T15:45:51.829909Z",
     "shell.execute_reply": "2023-06-02T15:45:51.828371Z",
     "shell.execute_reply.started": "2023-06-02T15:45:51.262031Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's check frequency for the word count for each page\n",
    "plt.hist(page_len, bins=100)\n",
    "plt.xlabel('Num. Word Count')\n",
    "plt.ylabel('Word Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T16:04:01.82804Z",
     "iopub.status.busy": "2023-06-01T16:04:01.827683Z",
     "iopub.status.idle": "2023-06-01T16:04:01.835889Z",
     "shell.execute_reply": "2023-06-01T16:04:01.834443Z",
     "shell.execute_reply.started": "2023-06-01T16:04:01.828014Z"
    }
   },
   "source": [
    "Majority of the page centers around 250 to 750 words. Its right tail goes up to almost 2,000 words. However, there are only a few pages that contain that many words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T15:45:51.832207Z",
     "iopub.status.busy": "2023-06-02T15:45:51.831343Z",
     "iopub.status.idle": "2023-06-02T15:45:58.081178Z",
     "shell.execute_reply": "2023-06-02T15:45:58.07986Z",
     "shell.execute_reply.started": "2023-06-02T15:45:51.83217Z"
    }
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(max_words=250, max_font_size=72, width=800, height=400).generate(\" \".join(all_tokens))\n",
    "\n",
    "plt.figure(figsize=(12, 18))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle kernels push -p /Users/macmini/Desktop/GoogleDrive/OxML_2023/code/Kaggle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
